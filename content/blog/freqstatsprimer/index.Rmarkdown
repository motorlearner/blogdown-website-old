---
# text
title:      "Frequentist Statistics Primer"
subtitle:   "p-values, confidence intervals, and error rates"
excerpt:    "All things frequentist statistics."

# metadata (NB bottom will show "see also: all posts with same tag")
author:     "Aslan B."
date:       2022-05-01
categories: 
- statistics
tags:
- statistics

# other
layout:     single
draft:      false
---

```{r setup, include = FALSE}

# load knitr
library(knitr)
# set chunk opts
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  include = TRUE,
  echo    = TRUE
)
# set seed
set.seed(123)
# display numbers to two decimals
options(digits = 1)

```

```{css, echo=FALSE}
/* make all images centered;
   no width parameter to preserve width set via ggsave;
   fig caption text style is set manually each time,
    there is probably an easier way to do this like
    make a css text class with those style params and
    then just apply that class, but I am too lazy atm
*/
img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}

/*  FONT SIZE
    - p = main text
    - li = list (could also use ol and ul for ordered, unordered)
    - h = headings
*/
p {
  font-size: 14px;
  text-align: justify;
  width: auto;
}
li{
  font-size: 14px;
  text-align: justify;
  width: 125%;
}
blockquote p{
  font-size: 13px;
  width: 120%;
}
h1{
  font-size: 16px;
}
h2{
  font-size: 14px;
}
```

In my experience, statistics courses often brush over the fundamentals and quickly---too quickly---move on to teach you different models and how to implement them. So, I decided to write a blogpost explaining the fundamentals of frequentist statistics. The goal is to give you a good understanding of the fundamental frequentist statistical concepts: p-values, confidence intervals, statistical power, etc. Enjoy! 


## In the Long Run

Statistical inference is based on probability theory. Mathematically speaking, probability is a scalar between zero and one, and the probability that any of multiple mutually exclusive events occurs is the sum of their individual probabilities. Intuitively speaking, >high probability< means we expect it and >low probability< means we‚Äôd be surprised if it happened. So far so good. But what exactly does probability quantify in the real world?
There are several interpretations of probability. But today, we are dealing with *frequentist statistics*. In this framework, probability refers to hypothetical long run *frequencies*. For example, when flipping a coin, the probability of heads is 0.5. That means, if we repeatedly flipped a coin,the proportion of heads would converge to 0.5 as the number of coin flips approaches infinity. You can see a simulated example in F1. 

<!-- plot: law of large numbers -->
<p style="text-align: center; font-size: 12px">
  <img src="plots/lln.svg" />
  <b> Figure 1. </b> 
  Twenty simulated series of 10,000 coin flips each. The y-axis shows the 
  proportion of heads. 
</p>

More generally, the probability that a process produces a certain outcome is the frequency at which that outcome is observed *in the long run*, i.e. *if the process is repeated infinitely often*. Note that, under this interpretation, it only makes sense to assign probability to repeatable events. Does it make sense to talk about the probability of getting a sum of 12 when rolling three dice? Yes, because you can roll three dice over and over again. Does it make sense to talk about the probability that your hypothesis is true? No, there is nothing to repeat here. 

> ‚úîÔ∏è **Probability as a long run frequency**  
Under the frequentist interpretatio, the probability that a process produces an outcome is the frequency at which that outcome is observed *in the long run*, i.e. *if the underlying process is repeated infinitely often*. 

## Setup

Statistical inference essentially means inferring some aspect of an unobservable probability distribution---often called the *population distribution*---using a random sample. Step by step, it looks something like this:

1. We are interested in some aspect of the population distribution.  
2. We draw a random sample from that population
3. We use information from the sample to infer something about (some aspect of) the population distribution.

Note that what exactly constitutes the population distribution and the random sample depends on the study design---in particular, which part is random: the inclusion of participants (as in surveys) or the allocation of participants (as in trials). But we don't need to worry about that. All that matters for us is the general concept.

Now, we need a specific example to work with, which will be as follows:

1. The population distribution is some distribution. It has an unknown mean $\mu$, which we are interested in. It also has a known standard deviation $\sigma=1$.  
2. We draw a random sample of size $N$ from that population distribution. We denote the sample mean $m$ and the sample standard deviation $s$.  
3. We use the sample mean $m$ to infer something about the population mean $\mu$.  

We will later pretend that *both* $\mu$ and $\sigma$ are unknown, in which case we will have to use both $m$ and $s$. But for now, $\sigma=1$ is known and $s$ can be ignored.

<!-- plot: overview -->
<p style="text-align: center; font-size: 12px">
  <img src="plots/overview.svg" />
  <b> Figure 2. </b> 
  The working example. We draw a sample of size \(N\) from a population 
  distribution with mean \(\mu\) and standard deviation \(\sigma\). We want to
  answer some question about \(\mu\). In our case, we know that the population 
  distribution is normal, and that \(\sigma=1\). 
</p>

An easy way to remember what the symbols ($\mu,\sigma,m,s,N$) stand for is: greek letter are for population parameters (latin ones for sample parameters) and letters that are pronounced with M at the beginning are for the mean (the ones with S are for the standard deviation). 

<table>
  <tr>
    <td>  </td>
    <th> Population </th>
    <th> Sample </th>
  </tr>
  <tr>
    <td> Mean </td>
    <td> \(\mu\) </td>
    <td> \(m\) </td>
  </tr>
  <tr>
    <td> Standard Deviation </td>
    <td> \(\sigma\) </td>
    <td> \(s\) </td>
  </tr>
  <tr>
    <td> Size </td>
    <td>  </td>
    <td> \(N\) </td>
  </tr>
</table>

So, what do we want to know about $\mu$? We might want to know whether it is greater or smaller than some value. We might want to know whether it is different from or similar to some value. Or, we might simply want an estimate of it. To answer any of these questions, we need the sampling distribution. 

## The Sampling Distribution

The sampling distribution exists for any sample statistic (sample mean, median, standard deviation, etc.) and it tells you how that sample statistic would be distributed if you computed it for an infinite series of random samples.

We will be using the sampling distribution of the sample mean $m$. In **Figure 3** you see twenty samples of size $N$, drawn from a population distribution with some mean $\mu$ and some standard deviation $\sigma$. The grey points are the sample values, and the colored squares are the sample means. 

<!-- plot: clt samples -->
<p style="text-align: center; font-size: 12px">
  <img src="plots/clt_sample.svg" />
  <b> Figure 3. </b> 
  Samples of size \(N\), drawn from a normal distribution with mean \(\mu\) (dashed line) 
  and standard deviation \(\sigma\).
</p>

Now, what if we continued doing this infinitely many times? We would get infinitely many sample means, which would form their own distribution. This is the sampling distribution of $m$. In **Figure 4**, you can see the sampling distribution of $m$ in colour (and the underlying population distribution in grey).

<!-- plot: clt distributions -->
<p style="text-align: center; font-size: 12px">
  <img src="plots/clt_dist.svg" />
  <b> Figure 4. </b> 
  The sampling distribution of \(m\), for three sample sizes \(N\). The samples 
  were drawn from the gray population distribution with mean \(\mu\) and standard deviation 
  \(\sigma\). The dashed line highlights \(\mu\). The x-axis shows the distance from 
  \(\mu\), measured in multiples of \(\sigma\).
</p>

The sampling distribution of $m$ has some important properties. First, it has the same mean as the underlying population distribution‚Äîi.e. it has mean $\mu$. Second, its spread decreases as the sample size $N$ increases‚Äîspecifically, it has standard deviation $\frac{\sigma}{\sqrt{N}}$. Third‚Äîmaybe not quite so obvious‚Äîit is a normal distribution. To sum up, the sampling distribution of $m$ is a normal distribution with mean $\mu$ and standard deviation $\frac{\sigma}{\sqrt{N}}$.

> üìù **The Central Limit Theorem**  
The sampling distribution of $m$ is a normal distribution with mean $\mu$ and standard deviation $\frac{\sigma}{\sqrt{N}}$ given almost any population distribution. The population distribution must have a finite mean $\mu$ and standard deviation $\sigma$, but other than that it can be whatever. There is a caveat: depending on the shape of the population distribution, the above holds only if $N$ is sufficiently large. For example, a sample size of 5 will probably be enough given a symmetric population distribution but it might not be enough given a heavily skewed population distribution. You can create your own population distribution and simulate the sampling distribution
[here](https://onlinestatbook.com/stat_sim/sampling_dist/). 

So, now we know what the sampling distribution is: if we drew infinitely many samples from a population distribution with mean $\mu$ and standard deviation $\sigma$, then all the sample means would be distributed according to the sampling distribution of $m$. But how is this useful? How can we use that knowledge to learn something about $\mu$? Let‚Äôs build some intuition. 

Say we draw a random sample of $N=15$ from our population with unknown mean $\mu$ and standard deviation $\sigma=1$. The sample is shown in **Figure 5**. The sample mean turns out to be $m=0.3$, and it is marked by the solid vertical line.

<!-- plot: sample -->
<p style="text-align: center; font-size: 12px">
  <img src="plots/sample.svg" />
  <b> Figure 5. </b> 
  Sample.
</p>

Let‚Äôs ask a simple question: $\mu\stackrel{?}{=}0$. Well, if we assume $\mu\stackrel{!}{=}0$, then our sample mean (solid vertical line) must have come from the distribution highlighted in **Figure 6** (the one with mean $0$). Just by looking at the figure, I think we can agree that this is not unlikely. So, $\mu$ could be $0$. 

<!-- plot: sampling distribution placement 1 -->
<p style="text-align: center; font-size: 12px">
  <img src="plots/sdistplace1.svg" />
  <b> Figure 6. </b> 
  Sampling distributions of \(m\) for different \(\mu\), given \(\sigma=1\) and \(N=15\).
  The highlighted sampling distribution shows how \(m\) would be distributed in the long
  run if \(\mu=-0\). 
</p>

Let‚Äôs repeat this with another value: $\mu\stackrel{?}{=}-0.5$. Again, if we assume $\mu\stackrel{!}{=}-0.5$, then our sample mean (solid vertical line) must have come from the distribution highlighted in **Figure 7** (the one with mean $-0.5$). Just by looking at the figure, I think we can agree that this is very unlikely (but not exactly impossible: the tails of the distribution are thin but never zero). So, we can conclude $\mu\ne -0.5$. 

<!-- plot: sampling distribution placement 2 -->
<p style="text-align: center; font-size: 12px">
  <img src="plots/sdistplace2.svg" />
  <b> Figure 6. </b> 
  Sampling distributions of \(m\) for different \(\mu\), given \(\sigma=1\) and \(N=15\).
  The highlighted sampling distribution shows how \(m\) would be distributed in the long run
  if \(\mu=-2\). 
</p>

We can center the sampling distribution of $m$ on any value, call it $\mu_0$. If we assume $\mu\stackrel{!}{=}\mu_0$, then our sample mean $m$ must have come from that distribution. If that is very unlikely, then we conclude $\mu\ne\mu_0$. That is a very rough sketch of how frequentist statistics works. Now, we will look at this in more detail. 

> ‚úîÔ∏è **The sampling distribution of $m$**  
If we assume that $\mu\stackrel{!}{=}\mu_0$, then our sample mean $m$ must have come from the sampling distribution with mean $\mu_0$. If that is very unlikely, we conclude that $\mu\ne\mu_0$.  

## Rejecting the Incompatible

Let's take a step back and forget about sampling distributions for a moment. Instead, 
imagine we are at a scientific conference, and we want to know whether our common friend
Rick is also at the conference. We know that Rick is always wearing a lab coat. We look 
carefully, but no one is wearing a lab coat. 

1. If Rick is at the conference, then someone will be wearing a lab coat. 
2. No one is wearing a lab coat. 
3. Therefore, Rick is not at the conference.

This is a valid argument called *modus tollens*, also known as 'denying the consequent'. 
Now, let's say we *do* see someone wearing a lab coat.

1. If Rick is at the conference, then someone will be wearing a lab coat. 
2. Someone is wearing a lab coat. 
3. --

We cannot conclude that Rick was at the conference.
We might have seen Rick in his lab coat, or we might have 
seen someone else wearing a lab coat. We simply cannot conclude anything. 

Below you see these two cases summarized in more abstract form. We start with a 
model/assumption that tells us what observation (O) to expect under a certain possible 
truth (T). Then we make the observation. Finally, if this observation is incompatible
with the possible truth, we reject the possible truth.

<table>
  <tr>
    <td>
      <i> 3. Model/Assumption </i>
    </td>
    <td>
      If T, then O.
    </td>
    <td>
      If T, then O.
    </td>
  </tr>
  <tr>
    <td>
      <i> 4. Observation </i>
    </td>
    <td>
      Not O.
    </td>
    <td>
      O.
    </td>
  </tr>
  <tr>
    <td>
      <i> 5. Conclusion </i>
    </td>
    <td>
      Therefore not T.
    </td>
    <td>
      -
    </td>
  </tr>
</table>

This is the same logic that is used in frequentist statistics. However, this was a 
minimalist presentation that left some steps implicit. Here is the same logic with all 
steps made explicit:

<table>
  <tr>
    <td style="width:34%">
      <i> 1. List all possible truths. </i> <br>
      \(T_1, T_2, T_3 ... \)
    </td>
    <td colspan="2">
      \(T_1\): Rick is at the conference. <br>
      \(T_2\): Rick is not at the conference.
    </td>
  </tr>
  <tr>
    <td>
      <i> 2. List all possible observations. </i> <br>
      \(O_1, O_2, O_3 ... \)
    </td>
    <td colspan="2">
      \(O_1\): Someone is wearing a lab coat. <br>
      \(O_2\): No one is wearing a lab coat.
    </td>
  </tr>
  <tr>
    <td>
      <i> 3. For each possible truth, define which 
      observations are compatible and which are incompatible. </i> <br>
      <img src="graphics/compatiblemapping.svg">
    </td>
    <td colspan="2">
      If \(T_1\), then \(O_1\). In other words, \(T_1\) is compatible with \(O_1\); it is incompatible 
      with everything else, i.e. \(O_2\). <br><br>
      If \(T_2\), then \(O_1\) or \(O_2\). In other words, \(T_2\) is compatible with \(O_1\) and \(O_2\);
      it is incompatible with everything else, i.e. nothing.
    </td>
  </tr>
  <tr>
    <td>
      <i> 4. Make an observation. </i>
    </td>
    <td style="width:33%">
      \(O_1\): Someone is wearing a lab coat.
    </td>
    <td style="width:33%">
      \(O_2\): No one is wearing a lab coat.
    </td>
  </tr>
  <tr>
    <td>
      <i> 5. Reject all possible truths that are incompatible with the observation. </i>
    </td>
    <td style="width:33%">
      Reject nothing.
    </td>
    <td style="width:33%">
      Reject \(T_1\). 
    </td>
  </tr>
  <tr>
    <td>
      <i> 6. The actual truth is somewhere among the remaining possible truths (which
      are compatible with the observation). </i>
    </td>
    <td style="width:33%">
      \(T_1\) or \(T_2\): Rick is or is not at the conference.
    </td>
    <td style="width:33%">
      \(T_2\): Rick is not at the conference.
    </td>
  </tr>
</table>

So you start with all possible truths, then make an observation, and
then _reject_ the possible truths that are _incompatible_ with the observation. You are
left with all the possible truths that are not rejected. The actual truth is somewhere in 
there. They key point is: the only way to conclude that the actual truth is *something* 
is to reject *everything else*. You can only reject!

If you have a lake full of fish, and you are looking for the one true 
fish, you cannot just cast your fishing pole and pull the true fish out of the lake. 
Instead, you have to remove all the other fish from the lake until you are left with the 
one true fish. (If you came here for good analogies you're probably in the wrong place.)

So now we know that our mode of inference is the rejection of possible truths that are
incompatible with our observation. But what does 'incompatible' really mean?
In our conference example, it meant 'logically impossible':
If T, then O *for sure* and 'not O' is *logically impossible* (if Rick---who is always
wearing a lab coat---is at the conference, then it is logically impossible that no one 
there will be wearing a lab coat). 
But many situations cannot be solved by logic alone---we need probability and statistics. 
In those cases, 'incompatible' means 'unlikely':
If T, then O *with high probability* and 'not O' is *with low probability*.
Under the frequentist interpretation of probability, this translates to:
If T, then O *in most cases in the long run* and 'not O' *in few cases in the long run*. 

So our mode of inference is the rejection of all possible truths under which our 
observation would be rare, in the long run. For example: if we repeatedly flipped a 
conventional coin 10 times, then we would get either 0/10 or 10/10 heads in only 0.2% of 
all cases, in the long run. So upon getting 0/10 or 10/10 heads, we will reject the notion 
that this is a conventional coin.

## The Null and the Alternative

Now, let's apply what we've learned to our `rnorm(n)` working example. Recall we are 
interested in the population mean $\mu$. Our observation is the sample mean $m$ from 
a random sample of size $N$. We will walk through the example using $N=15$.

*1. List all possible truths.*

We start with all possible truths about $\mu$: it could be *any* number. Recall that we 
can only conclude that $\mu$ is *something* by rejecting that $\mu$ is *everything else*. 
Accordingly, we divide all possible truths about $\mu$ into two parts: the 'something' 
we want to conclude and the 'everything else' that we need to reject in order to do so. 

The 'everything else' we need to reject is the *Null Hypothesis* $H_0$. The 'something' we
then conclude is the *alternative hypothesis* $H_1$. There are three fundamental 
versions of $H_0$ and $H_1$:

<table>
  <tr>
    <td>
    1a
    </td>
    <td>
    \(H_0: \mu \le \mu_0\) <br>
    \(H_1: \mu  >  \mu_0\)
    </td>
    <td>
    \(\mu\) is less or equal to some value \(\mu_0\) <br>
    \(\mu\) is greater than some value \(\mu_0\)
    </td>
  </tr>
  <tr>
    <td>
    1b
    </td>
    <td>
    \(H_0: \mu \ge \mu_0\) <br>
    \(H_1: \mu  <  \mu_0\)
    </td>
    <td>
    \(\mu\) is greater or equal to some value \(\mu_0\) <br>
    \(\mu\) is less than some value \(\mu_0\)
    </td>
  </tr>
  <tr>
    <td>
    2
    </td>
    <td>
    \(H_0: \mu  =  \mu_0\) <br>
    \(H_1: \mu \ne \mu_0\)
    </td>
    <td>
    \(\mu\) is equal to some value \(\mu_0\) <br>
    \(\mu\) is different from some value \(\mu_0\)
    </td>
  </tr>
</table>

Versions 1a and 1b are called *one-sided tests*. Note that they are basically opposites 
of each other. Version 2 is called a *two-sided test*. Technically, a two-sided test 
is just the combination of both one-sided tests, so it's not really fundamental. 

Note that $\mu_0$ is just some hypothetical value for $\mu$ that we are particularly 
interested in. We are often interested in specific hypothetical values for a given
parameter. Say you want to know whether a vaccine prevents more than 90% of infections. 
Your parameter is vaccine efficacy and you are asking if it's greater than 90%. Or, say
your want to know whether drinking coffee influences reaction time. Your parameter is 
the effect of coffee on reaction time and you are asking if it's different from zero. 
Of course, sometimes you are not interested in specific hypothetical values for a given 
parameter. Say you conduct a survey and ask people about their age. Your parameter is the 
population age, but you are simply asking what it is --- there is no value of interest. 
As we will see shortly, that situation also corresponds to one of the versions above. 

Now that we have listed all possible truths about $\mu$ in the form of $H_0$ and $H_1$, 
we can move on to the next step. 

*2. List all possible observations.*

We continue with all possible sample means $m$: it could by *any* number.

## The false rejection rate

*3. For each possible truth, define which observations are compatible and which are incompatible.*

Since we want to reject $H_0$, we need to define which $m$ would be incompatible with 
$H_0$. In the frequentist framework, 'incompatible' means 'rare, in the long run'. 
But how rare, exactly? Well, that's for us to decide---and we will later take a closer
look at how to do so. But for now, I will just go ahead and define 'rare' to mean 5%.
With that, here is how we define which $m$ are incompatible with $H_0$.

Take a look at **Figure 5**. The top row shows $H_0$ and $H_1$ for the one-sided cases
(on the left, in the middle) and for the two-sided case (on the right). In the one-sided 
case, $\mu_0$ is the most extreme value under $H_0$. In the two-sided case, $\mu_0$ is 
the only value under $H_0$. 
The bottom row shows a bunch of sampling distributions of $m$. All the red ones 


The bottom row shows the sampling distribution of $m$, centered on $\mu_0$ (dashed line). 
If $\mu=\mu_0$, then $m$ would be distributed like that, in the long run. 
The gray tail area is $\alpha=0.05$---one tail of 0.05 in the one-sided cases and two tails
of 0.025 each in the two-sided case. Note that the tails are never zero, they just become 
too small to see. If $\mu=\mu_0$, then we would see "gray $m$" in 5% of cases, in the long
run. These "gray $m$" are incompatible with $H_0$. In other words, if $m$ falls at least 
as far away from $H_0$ as the cutoff (solid line), then we will reject $H_0$. 

<!-- plot: h0h1 -->
<p style="text-align: center; font-size: 12px">
  <img src="plots/h0h1.svg" />
  <b> Figure 5. </b> 
  Set-up for one-sided tests (left, middle) and two-sided tests (right). The top row 
  shows the Null hypothesis \(H_0\), and the alternative hypothesis \(H_1\). The bottom 
  row shows the sampling distribution of \(m\), centered on \(\mu_0\). Note that the
  distribution is nonzero everywhere, but the tails become too thin to see them all the way out. 
  The gray area shows which \(m\) are incompatible with (icw) \(H_0\), the red area shows which
  \(m\) are compatible with (cw) \(H_0\). 
</p> 



So by setting $\alpha$, we define what it takes to reject $H_0$. There are two ways to 
describe what $\alpha$ means. First, it tells us how far away from $H_0$ the sample mean 
$m$ needs to fall in order to reject $H_0$: so far that, if $H_0$ were true, this would
happen in no more than a fraction $\alpha$ of all cases in the long run. Another way to put 
it is, that it tells us how often we'd make a false rejection: if $H_0$ were true, then we 
would falsely reject it in no more than a fraction $\alpha$ of all cases in the long run. 
Thus, $\alpha$ is our *false rejection rate*. 

So, what should we set $\alpha$ to?
So far, we have simply set it to 0.05, and we will stick with 0.05 as we move on. 
In fact, most studies simply set it to 0.05. But what is the justification? There is none! 
There is no good justification for always using 0.05. In fact, there is no good justification 
for always using *any* specific value. Instead, you should set $\alpha$ depending on the context 
of the research question and the available resources. We will look at this in more detail, 
later. For now, it's sufficient to know what $\alpha$ is. 

> ‚úîÔ∏è **The false rejection rate $\mathbf{\alpha}$**  
If $\mu$ was some hypothetical value, then we would falsely reject it in a small fraction 
$\alpha$ of all cases, in the long run. Thus, $\alpha$ is our *false rejection rate*. We
are in full control of $\alpha$, i.e. we decide what the false rejection rate is. 

## The p-value

*4. Make an observation.*

Next, we draw our sample of $N=15$ and compute the sample mean $m$. 

*5. Reject all possible truths that are incompatible with the observation.*

We have set $\alpha$ to define how far away from $H_0$ the sample mean $m$ needs to fall, 
in order to reject $H_0$. We have drawn a sample and computed $m$. Now, we will check 
how far away from $H_0$ our sample mean $m$ did fall, by computing the $p$-value. If 
$p\le\alpha$, our sample mean fell far enough from $H_0$ to reject it. 

To get $p$, we simply repeat the two steps from earlier with a slight adjustment. You can 
follow along in **Figure 6**. Earlier---before taking our sample---we defined how large the 
gray area $\alpha$ should be. This implied a cutoff , which
told us how far away from $H_0$ the sample mean $m$ needs to fall in order to reject $H_0$. 
Now---after taking our sample---we use our observed sample mean $m$ as the cutoff. 
This creates a gray area $p$. If $p\le\alpha$, our observed sample mean is far away from 
$H_0$, so we reject $H_0$. 

<!-- plot: p-values -->
<p style="text-align: center; font-size: 12px">
  <img src="plots/pvalue.svg" />
  <b> Figure 6. </b> Caption here. 
</p> 

Just as with $\alpha$, there are two ways to describe what the $p$-value means. First, 
it tells us how far away our sample mean $m$ is from $H_0$: so far that, if $H_0$ were 
true, this would happen in no more than a fraction $p$ of all cases in the long run.
Second, it tells us the lowest false rejection rate under which we would reject $H_0$, 
given our observed sample mean $m$.

<!-- plot: p-value curves -->
<p style="text-align: center; font-size: 12px">
  <img src="plots/pvaluecurve.svg" />
  <b> Figure. </b> Caption here. 
</p> 

<!-- plot: confidence intervals -->
<p style="text-align: center; font-size: 12px">
  <img src="plots/ci.svg" />
  <b> Figure. </b> Caption here. 
</p>

<!-- plot: confidence intervals by n -->
<p style="text-align: center; font-size: 12px">
  <img src="plots/ci_n.svg" />
  <b> Figure. </b> Caption here. 
</p>

<!-- plot: rejection rate -->
<p style="text-align: center; font-size: 12px">
  <img src="plots/rejrate.svg" />
  <b> Figure. </b> Caption here. 
</p>

<table>
  <tr>
    <th>
      Decision
    </th>
    <th>
      Truth
    </th>
    <th>
      Evaluation
    </th>
    <th>
      Rate
    </th>
  </tr>
    <td rowspan="2">
      Rejection
    </td>
    <td>
      Value in question is the true value.
    </td>
    <td>
      False
    </td>
    <td>
      \(\alpha\)
    </td>
  <tr>
    <td>
      Value in question is not the true value.
    </td>
    <td>
      True
    </td>
    <td>
      \(1-\beta\)
    </td>
  </tr>
  <tr>
    <td rowspan="2">
      Non-rejection
    </td>
    <td>
      Value in question is the true value.
    </td>
    <td>
      True
    </td>
    <td>
      \(1-\alpha\)
    </td>
  </tr>
  <tr>
    <td>
      Value in question is not the true value.
    </td>
    <td>
      False
    </td>
    <td>
      \(\beta\)
    </td>
  </tr>
</table>

<!-- plot: alpha beta inference -->
<p style="text-align: center; font-size: 12px">
  <img src="plots/rejrate_inference.svg" />
  <b> Figure. </b> Caption here. 
</p>

<!-- plot: rejection rate by alpha -->
<p style="text-align: center; font-size: 12px">
  <img src="plots/rejrate_alpha.svg" />
  <b> Figure. </b> Caption here. 
</p>

<!-- plot: rejection rate by n -->
<p style="text-align: center; font-size: 12px">
  <img src="plots/rejrate_n.svg" />
  <b> Figure. </b> Caption here. 
</p>

<!-- plot: rejection rate heatmap by alpha -->
<p style="text-align: center; font-size: 12px">
  <img src="plots/rejrateheat_alpha.svg" />
  <b> Figure. </b> Caption here. 
</p>

<!-- plot: rejection rate heatmap by sigma -->
<p style="text-align: center; font-size: 12px">
  <img src="plots/rejrateheat_sigma.svg" />
  <b> Figure. </b> Caption here. 
</p>

<!-- plot: rejection rate heatmap by sigma standardized -->
<p style="text-align: center; font-size: 12px">
  <img src="plots/rejrateheat_sigma_std.svg" />
  <b> Figure. </b> Caption here. 
</p>

